{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mDMgSstPYv0P"
   },
   "source": [
    "# Text Classification\n",
    "\n",
    "### About Data\n",
    "<pre>\n",
    "The data contains 20 classes document that we have to classify.\n",
    "- <b>Number of datapoints</b> : 18712.\n",
    "- <b>Number of class</b> : 20.\n",
    "- <b>Data format</b> : Txt File.\n",
    "            \n",
    "            documents/\n",
    "                      alt.atheism_49960.txt\n",
    "                      alt.atheism_51119.txt\n",
    "                      ...\n",
    "                     \n",
    "             where <b> alt.atheism</b> indicates the class name.\n",
    "\n",
    "</pre>\n",
    "\n",
    "### Bussiness Constrain\n",
    "<pre>\n",
    "\n",
    "- To develop a model that will help to classify the format to 20 classes provided.\n",
    "- Low latency.\n",
    "- Accuracy can be taken as performance matrix as its multiclass classification and data are nearly balance.\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pathlib\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "import keras\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "64U9NzWFYv0V",
    "outputId": "f3f19ed2-f637-4a8c-cff7-40a603025e96"
   },
   "outputs": [],
   "source": [
    "### count plot of all the class labels.\n",
    "dir_path = \"documents/\"\n",
    "classes = {}\n",
    "for file in os.listdir(dir_path):\n",
    "    class_name = file.split(\"_\")\n",
    "    if class_name[0] in classes:\n",
    "        classes[class_name[0]] +=1\n",
    "    else:\n",
    "        classes[class_name[0]]=0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = list(classes.keys())\n",
    "y = list(classes.values())\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.title(\"Counts of classes\")\n",
    "sns.barplot(x = y,y = x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VlqYFVI3Yv0k"
   },
   "source": [
    "#### sample document\n",
    "<pre>\n",
    "<font color='blue'>\n",
    "Subject: A word of advice\n",
    "From: jcopelan@nyx.cs.du.edu (The One and Only)\n",
    "\n",
    "In article < 65882@mimsy.umd.edu > mangoe@cs.umd.edu (Charley Wingate) writes:\n",
    ">\n",
    ">I've said 100 times that there is no \"alternative\" that should think you\n",
    ">might have caught on by now.  And there is no \"alternative\", but the point\n",
    ">is, \"rationality\" isn't an alternative either.  The problems of metaphysical\n",
    ">and religious knowledge are unsolvable-- or I should say, humans cannot\n",
    ">solve them.\n",
    "\n",
    "How does that saying go: Those who say it can't be done shouldn't interrupt\n",
    "those who are doing it.\n",
    "\n",
    "Jim\n",
    "--\n",
    "Have you washed your brain today?\n",
    "</font>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing\n",
    "<pre>\n",
    "\n",
    "<font color=\"Red\"><b>Point of Action</b></font>\n",
    "- Since we are classifying the data that are mail or article so every thing has head,body.So task can be divided into 2.\n",
    "- For head we use subject and mail.\n",
    "- For body we preprocess everything and save all.\n",
    "<br>\n",
    "<font color=\"Blue\"><b>TEXT PREPROCESS TECHNIQUE</b></font>\n",
    "\n",
    "1. Get mail from the Text filter out all the punctuation, @ from and front part before @. as it usually contain name.\n",
    "2. Get part that contain only Subject.\n",
    "3. For Body filter out : \n",
    "    - Punctutaion.\n",
    "    - Name of person.\n",
    "    - Number if any.\n",
    "    - Lower down the case.\n",
    "    - Replace shortcut with its full form.\n",
    "    - Remove space.\n",
    "    - Remove newline.\n",
    "    - Remove tabs if any.\n",
    "    - Remove words less than or equal to 2.\n",
    "    - Remove Stopwords - <font color=\"Brown\">Using NLTK for stopword</font>.\n",
    "    - Remove words greater than 20.\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18828/18828 [00:16<00:00, 1174.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Time taken :  0:00:16.054268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "start_time = datetime.now()\n",
    "mails = []\n",
    "for i in tqdm(os.listdir(dir_path)):\n",
    "    processed_mail = \"\"\n",
    "    with open(dir_path+\"/\" + i,\"r\") as f:\n",
    "        text = f.read()\n",
    "        email = re.findall('[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+',text)\n",
    "        # since first word in email are name so not so use full and .com .uk in mail are also not use ful so getting only the \n",
    "        # domain name for the email\n",
    "        for mail in email:\n",
    "            text = text.replace(mail,\" \")\n",
    "            mail = mail.split(\"@\")\n",
    "            mail = mail[1].split(\".\")\n",
    "            for m in mail:\n",
    "                if len(m)>2 and m != \"com\":\n",
    "                    m = m.lower()\n",
    "                    processed_mail += m + \" \" \n",
    "                    \n",
    "        mails.append(processed_mail.strip())\n",
    "        \n",
    "   \n",
    "    # writting to the file\n",
    "    with open(dir_path+\"/\" + i,\"w\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "print(\"Done\")\n",
    "print(\"Time taken : \", datetime.now()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mantis netcom mantis'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mails[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18828/18828 [00:15<00:00, 1246.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# Reading the after processing for mails\n",
    "with open(dir_path+\"/\" + \"alt.atheism_51060.txt\",\"r\") as f:  \n",
    "    text = f.readlines()\n",
    "   \n",
    "subjects = []\n",
    "one = []\n",
    "to_remove_sub = []\n",
    "for i in tqdm(os.listdir(dir_path)):\n",
    "    one = []\n",
    "    without_sub = \"\"\n",
    "    with open(dir_path+\"/\" + i,\"r\") as f:  \n",
    "        text = f.readlines()\n",
    "        for t in text:\n",
    "           \n",
    "            orgi_t = t\n",
    "            t = t.lower() \n",
    "            if t.startswith(\"subject:\"):\n",
    "         \n",
    "                to_remove_sub.append(orgi_t)\n",
    "                t = re.sub(\"subject:\",\"\",t) # removing subject\n",
    "                t = re.sub(\"re:\",\"\",t) # remoing re  \n",
    "                t = re.sub(\":\",\"\",t) # removing :\n",
    "                t = t.replace(\"′\", \"'\").replace(\"’\", \"'\")\\\n",
    "               .replace(\"won't\", \"will not\").replace(\"cannot\", \"can not\").replace(\"can't\", \"can not\")\\\n",
    "               .replace(\"n't\", \" not\").replace(\"what's\", \"what is\").replace(\"it's\", \"it is\")\\\n",
    "               .replace(\"'ve\", \" have\").replace(\"i'm\", \"i am\").replace(\"'re\", \" are\")\\\n",
    "               .replace(\"he's\", \"he is\").replace(\"she's\", \"she is\")\\\n",
    "               .replace(\"'ll\", \" will\")  # replacing values\n",
    "                t = re.sub(r'[^\\w\\s]', ' ', t) # removing punctuation\n",
    "                t = re.sub(r\"[^a-zA-Z0-9]+\",\" \",t) # removing special charater \n",
    "                t = re.sub(\"\\n\",\" \",t) # removing new line\n",
    "                t = re.sub(\"\\t\",\" \",t)  # removing tabs  \n",
    "                t = re.sub(\"\\S*\\d\\S*\", \" \", t).strip() # removing numbers\n",
    "                if t not in one:\n",
    "                    one.append(t)\n",
    "                    \n",
    "            else:\n",
    "                # also remove the line from, to , write to as it conatin mail which is already extraacted\n",
    "                if not t.startswith(\"from:\") and (not t.startswith(\"write to:\")) and t!=\"\\n\":\n",
    "                   \n",
    "                    without_sub  += orgi_t\n",
    "                \n",
    "                             \n",
    "        t = \" \".join(one).strip()\n",
    "        subjects.append(t)\n",
    "        \n",
    "    with open(dir_path+\"/\" + i,\"w\") as f: \n",
    "        f.write(without_sub)\n",
    "#     print(without_sub)\n",
    "   \n",
    "#     break\n",
    "   \n",
    "    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alt atheism faq introduction to atheism'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KavKDD9FYv0p",
    "outputId": "0b87ab7b-46df-4995-eaca-4f5831ad223e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AAIC-The course that gets you HIRED'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"AAIC-The course that gets you HIRED(AAIC - Der Kurs, der Sie anstellt)\"\n",
    "re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "obReqs55Yv0v",
    "outputId": "10770414-9be0-4d63-9587-5363a8c10c4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'their is the'"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"their is the <life is hard sdfksdkflskdlgskldgkslkglskdg> [ok is ha] (ofkdafl)\"\n",
    "re.sub(\"[\\<\\(\\[].*?[\\)\\]\\>]\", \"\", x).strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word monty thon'"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blah = \"word word: monty py: thon\"\n",
    "re.sub(r'\\w+:\\s?','',blah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' kjhkjhkjh '"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = \"_kjhkjhkjh_\"\n",
    "re.sub(r\"[^a-zA-Z0-9]+\",\" \",t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whole text preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = stopwords.words('english')\n",
    "stopword = set(stopword)\n",
    "final_text = []\n",
    "def preprocess(dir_path):\n",
    "    \n",
    "    for i in tqdm(os.listdir(dir_path)):\n",
    "        processed_text = \"\"\n",
    "        with open(dir_path+\"/\" + i,\"r\") as f:\n",
    "            #reading the file\n",
    "            text = f.read()\n",
    "                     \n",
    "            # lower the text\n",
    "            text =text.lower()\n",
    "            # remove all the thing inside bracket\n",
    "            text = re.sub(\"[\\<\\(\\[].*?[\\)\\]\\>]\", \"\", text).strip()\n",
    "            # change shortform \n",
    "            text = text.replace(\"′\", \"'\").replace(\"’\", \"'\")\\\n",
    "                       .replace(\"won't\", \"will not\").replace(\"cannot\", \"can not\").replace(\"can't\", \"can not\")\\\n",
    "                       .replace(\"n't\", \" not\").replace(\"what's\", \"what is\").replace(\"it's\", \"it is\")\\\n",
    "                       .replace(\"'ve\", \" have\").replace(\"i'm\", \"i am\").replace(\"'re\", \" are\")\\\n",
    "                       .replace(\"he's\", \"he is\").replace(\"she's\", \"she is\")\\\n",
    "                       .replace(\"'ll\", \" will\") \n",
    "            # remove special character  and punctuation\n",
    "            text = re.sub(r'[^\\w\\s]', ' ', text) \n",
    "            text = re.sub(r\"[^a-zA-Z0-9]+\",\" \",text) \n",
    "            # remove new line, tabs, \\ , -\n",
    "            text = re.sub(\"\\n\",\" \",text)\n",
    "            text = re.sub(\"\\t\",\" \",text) \n",
    "            text = re.sub(\"-\",\" \",text)\n",
    "            # reject everything that ends with : as they are subjects \n",
    "            text = re.sub(r'\\w+:\\s?','',text)\n",
    "            # remove numbers\n",
    "            text = re.sub(\"\\S*\\d\\S*\", \" \", text)\n",
    "            # remove multiple spaces\n",
    "            text = re.sub('\\\\s+', ' ', text)\n",
    "                 \n",
    "            # remove word that are less than one \n",
    "            for word in text.split(\" \"):\n",
    "                if (len(word)>2) and (word not in stopword) and (len(word)<=20):\n",
    "                    \n",
    "                    processed_text +=word + \" \"\n",
    "                \n",
    "        final_text.append(processed_text.strip())  \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "            \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18828/18828 [00:10<00:00, 1764.97it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocess(dir_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining subjects, emails and text together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.DataFrame()\n",
    "data_frame[\"subject\"] = subjects\n",
    "data_frame[\"mails\"] = mails\n",
    "data_frame[\"processed_text\"] = final_text\n",
    "# print(final_text),len(subjects),len(mails)\n",
    "data_frame.head()\n",
    "## saving the dataframe\n",
    "data_frame.to_csv(\"final_data.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>mails</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alt atheism faq atheist resources</td>\n",
       "      <td>mantis netcom mantis</td>\n",
       "      <td>archive name atheism resources alt atheism arc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alt atheism faq introduction to atheism</td>\n",
       "      <td>mantis mantis mantis</td>\n",
       "      <td>archive name atheism introduction alt atheism ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gospel dating</td>\n",
       "      <td>dbstu1 tu-bs mimsy umd edu umd edu</td>\n",
       "      <td>article writes well john quite different neces...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>university violating separation of church state</td>\n",
       "      <td>mantis kepler unh edu</td>\n",
       "      <td>writes recently ras ordered none resisted care...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soc motss et al princeton axes matching funds ...</td>\n",
       "      <td>watson ibm com harder ccr-p ida org harder ccr...</td>\n",
       "      <td>article writes however hate economic terrorism...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             subject  \\\n",
       "0                  alt atheism faq atheist resources   \n",
       "1            alt atheism faq introduction to atheism   \n",
       "2                                      gospel dating   \n",
       "3    university violating separation of church state   \n",
       "4  soc motss et al princeton axes matching funds ...   \n",
       "\n",
       "                                               mails  \\\n",
       "0                               mantis netcom mantis   \n",
       "1                               mantis mantis mantis   \n",
       "2                 dbstu1 tu-bs mimsy umd edu umd edu   \n",
       "3                              mantis kepler unh edu   \n",
       "4  watson ibm com harder ccr-p ida org harder ccr...   \n",
       "\n",
       "                                      processed_text  \n",
       "0  archive name atheism resources alt atheism arc...  \n",
       "1  archive name atheism introduction alt atheism ...  \n",
       "2  article writes well john quite different neces...  \n",
       "3  writes recently ras ordered none resisted care...  \n",
       "4  article writes however hate economic terrorism...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"final_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining the subject , mail and processd_text\n",
    "df[\"txt_sub_emails\"] = df[\"subject\"] + \" \" + df[\"mails\"] + \" \" + df[\"processed_text\"]\n",
    "# adding class to the database\n",
    "data_path = \"documents\"\n",
    "classes = []\n",
    "for doc in os.listdir(data_path):\n",
    "    \n",
    "    class_name = doc.split(\"_\")[0]\n",
    "    classes.append(class_name)\n",
    "\n",
    "df[\"classes\"] = classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject            True\n",
       "mails              True\n",
       "processed_text     True\n",
       "txt_sub_emails     True\n",
       "classes           False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject           0\n",
       "mails             0\n",
       "processed_text    0\n",
       "txt_sub_emails    0\n",
       "classes           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data :  18712\n",
      "No of train data :  14034\n",
      "No of val data :  4678\n"
     ]
    }
   ],
   "source": [
    "### spliting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_data = df[\"txt_sub_emails\"]\n",
    "y_data = df[\"classes\"]\n",
    "\n",
    "train_x , val_x , train_y, val_y = train_test_split(x_data,y_data,train_size=0.75,shuffle=True,stratify=y_data)\n",
    "print(\"Total data : \",df.shape[0])\n",
    "print(\"No of train data : \", train_x.shape[0])\n",
    "print(\"No of val data : \", val_x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245      the inimitable rushdie an anecdote about islam...\n",
       "17592    clinton press briefing by george stephanopoulo...\n",
       "14852    some questions from a new christian empros emp...\n",
       "17054    freedom in u s a surya ucla edu brown edu virg...\n",
       "43       political atheists cwru edu gap caltech edu cc...\n",
       "                               ...                        \n",
       "11008    secret algorithm clipper chip and crypto key e...\n",
       "13379    a good place for back surgery panix cbnewsg at...\n",
       "9570     bob vesterman s plan to generate fan interest ...\n",
       "13994    keeping spacecraft on after funding cuts acces...\n",
       "645      alt atheism faq constructing a logical argumen...\n",
       "Name: txt_sub_emails, Length: 14034, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape,train_y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum :  17\n",
      "Maximum :  44659\n"
     ]
    }
   ],
   "source": [
    "def count_min_max_sent_word(dataframe):\n",
    "    min_sent = 1000000\n",
    "    max_sent = -100000\n",
    "    for sent in dataframe:\n",
    "        sent = str(sent)\n",
    "        min_sent = min(min_sent,len(sent))\n",
    "        max_sent = max(max_sent,len(sent))\n",
    "        if len(sent)==3:\n",
    "            print(sent)\n",
    "            break\n",
    "    \n",
    "            \n",
    "        \n",
    "    print(\"Maximum : \", min_sent)\n",
    "    print(\"Maximum : \", max_sent)\n",
    "        \n",
    "count_min_max_sent_word(x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Char level tokenizing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14034/14034 [00:01<00:00, 11307.57it/s]\n",
      "100%|██████████| 4678/4678 [00:00<00:00, 12815.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken :  0:00:01.609828\n",
      "Oringinal train size:  14034 After char level :  14034\n",
      "Original val size :  4678 After char level :  4678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "df_char_train = []\n",
    "for i in tqdm(train_x):\n",
    "    row_char = []\n",
    "    for char in i:\n",
    "        row_char.append(char)\n",
    "    df_char_train.append(row_char)\n",
    "\n",
    "## validation data\n",
    "df_char_val = []\n",
    "for i in tqdm(val_x):\n",
    "    row_char = []\n",
    "    for char in i:\n",
    "        row_char.append(char)\n",
    "    df_char_val.append(row_char)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "print(\"Total time taken : \", datetime.now()-start_time)\n",
    "print(\"Oringinal train size: \",train_x.shape[0],\"After char level : \", len(df_char_train))\n",
    "print(\"Original val size : \",val_x.shape[0],\"After char level : \", len(df_char_val))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing for word level incoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_string(x):\n",
    "    return str(x)\n",
    "df[\"txt_sub_emails\"] = df[\"txt_sub_emails\"].apply(make_string)\n",
    "x_data = np.array(df[\"txt_sub_emails\"])\n",
    "tokenizer_data = Tokenizer(num_words=20000)\n",
    "tokenizer_data.fit_on_texts(x_data)\n",
    "\n",
    "# for the train data\n",
    "text_sequences_train = tokenizer_data.texts_to_sequences(train_x)\n",
    "# for the valalidation data\n",
    "text_sequences_val = tokenizer_data.texts_to_sequences(val_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing for char-level encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_data = Tokenizer(num_words=20000)\n",
    "tokenizer_data.fit_on_texts(df_char_train)\n",
    "\n",
    "# for the train data\n",
    "text_sequences_train_char = tokenizer_data.texts_to_sequences(df_char_train)\n",
    "# for the valalidation data\n",
    "text_sequences_val_char = tokenizer_data.texts_to_sequences(df_char_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the token for unique category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "## ---------------- for train data-------------------------\n",
    "y_train = train_y.values\n",
    "##------------------------changing into 2 dim ----------------\n",
    "y_train = y_train.reshape((y_train.shape[0],1))\n",
    "## ------------ for validation data---------------\n",
    "y_val = val_y.values\n",
    "## ------------ changing into 2 dim\n",
    "y_val = y_val.reshape((y_val.shape[0],1))\n",
    "# define one hot encoding\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "# transform data\n",
    "onehot = encoder.fit(y_train.reshape((y_train.shape[0],1)))\n",
    "y_train = onehot.transform(y_train) # for train data\n",
    "y_val = onehot.transform(y_val) # for validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The y_train  shape :  14034\n",
      "The val shape  shape :  4678\n"
     ]
    }
   ],
   "source": [
    "print(\"The y_train  shape : \", y_train.shape[0])\n",
    "print(\"The val shape  shape : \",y_val.shape[0])\n",
    "\n",
    "assert y_train.shape[0]==len(text_sequences_train_char) and y_val.shape[0]== len(text_sequences_val_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After padding shape of train data :  (14034, 100)\n",
      "\n",
      "The data in vector : \n"
     ]
    }
   ],
   "source": [
    "max_review_length = 100\n",
    "X_train = sequence.pad_sequences(text_sequences_train_char, maxlen=max_review_length)\n",
    "X_val = sequence.pad_sequences(text_sequences_val_char, maxlen=max_review_length)\n",
    "\n",
    "print(\"After padding shape of train data : \",X_train.shape)\n",
    "print(\"\")\n",
    "print(\"The data in vector : \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Embedding Glove Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('glove.6B.100d.txt',encoding=\"utf8\")\n",
    "embeddings_index = dict()\n",
    "\n",
    "for line in f:\n",
    "    \n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = values[1:]\n",
    "    embeddings_index[word] = coefs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Char Embedding Glov Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, 'e': 2, 'a': 3, 'i': 4, 's': 5, 't': 6, 'n': 7, 'r': 8, 'o': 9, 'l': 10, 'c': 11, 'd': 12, 'u': 13, 'm': 14, 'p': 15, 'g': 16, 'h': 17, 'y': 18, 'w': 19, 'b': 20, 'f': 21, 'v': 22, 'k': 23, 'x': 24, 'j': 25, 'z': 26, 'q': 27, '1': 28, '-': 29, '2': 30, '0': 31, '3': 32, '6': 33, '4': 34, '5': 35, '8': 36, '7': 37, '9': 38}\n"
     ]
    }
   ],
   "source": [
    "f = open(\"glove_char_300d.txt\",encoding=\"utf8\")\n",
    "embeddings_index_char = dict()\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    char = values[0]\n",
    "    vectors = values[1:]\n",
    "    assert len(vectors) == 300\n",
    "    embeddings_index_char[char] = vectors\n",
    "    \n",
    "# print(embeddings_index_char.keys) \n",
    "print(tokenizer_data.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Level embedding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total token for the data :  94253\n"
     ]
    }
   ],
   "source": [
    "# embedding_matrix\n",
    "val =  len(tokenizer_data.word_index)\n",
    "print(\"Total token for the data : \",val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer_data.word_index)\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, i in tokenizer_data.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of embedding matrix is : (94253, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "         7064,  6316,     1,  6990,  7064,  6316,     1,  5690,  1474,\n",
       "          370,  2760,   107,  1827,    32,    58,  5690,  1474, 17937,\n",
       "          236,  1319,  1267,     2,     7,   503,    27,    63,   524,\n",
       "           41,   174,   524, 12465, 17937,   347,  6316,  5769,  2690,\n",
       "          174]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The shape of embedding matrix is :\",embedding_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Char level embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer_data.word_index)\n",
    "embedding_matrix = np.zeros((vocab_size+1, 300))\n",
    "for word, i in tokenizer_data.word_index.items():\n",
    "    embedding_vector = embeddings_index_char.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 100, 100)     9425300     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1 (Conv1D)                 (None, 94, 16)       11216       ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " conv2 (Conv1D)                 (None, 94, 16)       11216       ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " conv3 (Conv1D)                 (None, 94, 16)       11216       ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 94, 48)       0           ['conv1[0][0]',                  \n",
      "                                                                  'conv2[0][0]',                  \n",
      "                                                                  'conv3[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 47, 48)       0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " aftepollconv1 (Conv1D)         (None, 41, 16)       5392        ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " afterpollconv2 (Conv1D)        (None, 41, 16)       5392        ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " afterpollconv3 (Conv1D)        (None, 41, 16)       5392        ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 41, 48)       0           ['aftepollconv1[0][0]',          \n",
      "                                                                  'afterpollconv2[0][0]',         \n",
      "                                                                  'afterpollconv3[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 20, 48)      0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " aftepollconv11 (Conv1D)        (None, 14, 16)       5392        ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 224)          0           ['aftepollconv11[0][0]']         \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 224)          0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 20)           4500        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 20)           420         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,485,436\n",
      "Trainable params: 60,136\n",
      "Non-trainable params: 9,425,300\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## creating the model\n",
    "from tensorflow.keras.models import Model, load_model,Sequential\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "      \n",
    "x_input= keras.layers.Input((100,)) \n",
    "x_inpu = keras.layers.Embedding(val,100,input_length=100,weights=[embedding_matrix],trainable=False)(x_input)\n",
    "conv1  = keras.layers.Conv1D(16,7,activation=\"relu\",name=\"conv1\")(x_inpu)\n",
    "conv2 = keras.layers.Conv1D(16,7,activation=\"relu\",name=\"conv2\")(x_inpu)\n",
    "conv3 = keras.layers.Conv1D(16,7,activation=\"relu\",name= \"conv3\")(x_inpu)\n",
    "merger = tf.keras.layers.Concatenate(axis=-1)([conv1, conv2,conv3])\n",
    "x_p = keras.layers.MaxPool1D()(merger)\n",
    "conv1  = keras.layers.Conv1D(16,7,activation=\"relu\",name=\"aftepollconv1\")(x_p)\n",
    "conv2 = keras.layers.Conv1D(16,7,activation=\"relu\",name=\"afterpollconv2\")(x_p)\n",
    "conv3 = keras.layers.Conv1D(16,7,activation=\"relu\",name=\"afterpollconv3\")(x_p)\n",
    "merger = tf.keras.layers.Concatenate(axis=-1)([conv1, conv2,conv3])\n",
    "x_p = keras.layers.MaxPool1D()(merger)\n",
    "conv1  = keras.layers.Conv1D(16,7,activation=\"relu\",name=\"aftepollconv11\")(x_p)\n",
    "x = keras.layers.Flatten()(conv1)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "# x = keras.layers.Dense(256,activation=\"relu\")(x)\n",
    "# x = keras.layers.Dense(128,activation=\"relu\")(x)\n",
    "# x = keras.layers.Dense(64,activation=\"relu\")(x)\n",
    "x = keras.layers.Dense(20,activation=\"relu\")(x)\n",
    "output = keras.layers.Dense(20,activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=x_input,outputs=output)\n",
    "\n",
    "model.summary()\n",
    "# model.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "220/220 [==============================] - 11s 49ms/step - loss: 1.3753 - accuracy: 0.5239 - val_loss: 1.3625 - val_accuracy: 0.5329\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 11s 48ms/step - loss: 1.3435 - accuracy: 0.5358 - val_loss: 1.3349 - val_accuracy: 0.5385\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 11s 49ms/step - loss: 1.3267 - accuracy: 0.5385 - val_loss: 1.3189 - val_accuracy: 0.5455\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 11s 48ms/step - loss: 1.2949 - accuracy: 0.5499 - val_loss: 1.3024 - val_accuracy: 0.5541\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 11s 50ms/step - loss: 1.2686 - accuracy: 0.5532 - val_loss: 1.2846 - val_accuracy: 0.5599\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 10s 47ms/step - loss: 1.2479 - accuracy: 0.5658 - val_loss: 1.2754 - val_accuracy: 0.5652\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 10s 47ms/step - loss: 1.2360 - accuracy: 0.5659 - val_loss: 1.2807 - val_accuracy: 0.5607\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 11s 48ms/step - loss: 1.2176 - accuracy: 0.5789 - val_loss: 1.2493 - val_accuracy: 0.5718\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 11s 49ms/step - loss: 1.1918 - accuracy: 0.5839 - val_loss: 1.2542 - val_accuracy: 0.5712\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 11s 49ms/step - loss: 1.1793 - accuracy: 0.5856 - val_loss: 1.2372 - val_accuracy: 0.5785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d50f67c850>"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch = 10\n",
    "batch_size = 64\n",
    "# optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,validation_data=[X_val,y_val],batch_size=batch_size,epochs=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "220/220 [==============================] - 11s 46ms/step - loss: 1.1485 - accuracy: 0.6010 - val_loss: 1.2274 - val_accuracy: 0.5782\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 10s 46ms/step - loss: 1.1470 - accuracy: 0.5958 - val_loss: 1.2243 - val_accuracy: 0.5825\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 11s 50ms/step - loss: 1.1453 - accuracy: 0.5968 - val_loss: 1.2245 - val_accuracy: 0.5836\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 11s 50ms/step - loss: 1.1388 - accuracy: 0.6020 - val_loss: 1.2220 - val_accuracy: 0.5838\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 11s 49ms/step - loss: 1.1351 - accuracy: 0.6005 - val_loss: 1.2231 - val_accuracy: 0.5840\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 11s 48ms/step - loss: 1.1388 - accuracy: 0.6018 - val_loss: 1.2209 - val_accuracy: 0.5851\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 11s 49ms/step - loss: 1.1332 - accuracy: 0.6070 - val_loss: 1.2195 - val_accuracy: 0.5866\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 11s 48ms/step - loss: 1.1324 - accuracy: 0.6046 - val_loss: 1.2218 - val_accuracy: 0.5870\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 10s 47ms/step - loss: 1.1321 - accuracy: 0.6030 - val_loss: 1.2174 - val_accuracy: 0.5881\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 11s 48ms/step - loss: 1.1274 - accuracy: 0.6026 - val_loss: 1.2205 - val_accuracy: 0.5857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d505b95d60>"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We are heating the plateau so reducing the learnig rate\n",
    "\n",
    "epoch = 10\n",
    "batch_size = 64\n",
    "\n",
    "# optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,validation_data=[X_val,y_val],batch_size=batch_size,epochs=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_val[89].reshape(1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 18)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred),np.argmax(y_val[89])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation \n",
    "\n",
    "<pre>\n",
    "- Model was trained with learning rate of __0.0001 and 0.001__.\n",
    "\n",
    "- When the learning rate was 0.001 model tends to over fit after certain time.\n",
    "\n",
    "- The __filter size__ was change from __3 to 7__ to reduce the __parameter__ of the model.\n",
    "\n",
    "- Embedding layers use is of glob embedding which seem to perform good.\n",
    "\n",
    "- After we kept hitting the __Plateau__ train was terminated and accuracy was calculated.\n",
    "\n",
    "- The overall accuracy was found to be around __58 Percent__.\n",
    "\n",
    "- <font color=\"Blue\" size=\"4\"><b>To Remember</b></font>\n",
    "\n",
    "1. The filter in conv1d can act as n-grams.\n",
    "2. The inital size of the metrix should be one dimension to pass through embedding layers which give the dimesion of word vector.\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9cg4L1V4Yv1d"
   },
   "source": [
    "### Model-2 : Using 1D convolutions with character embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 100, 300)          11700     \n",
      "                                                                 \n",
      " first_conv (Conv1D)         (None, 94, 16)            33616     \n",
      "                                                                 \n",
      " Second_conv (Conv1D)        (None, 88, 16)            1808      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 44, 16)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " First_conv_1 (Conv1D)       (None, 38, 16)            1808      \n",
      "                                                                 \n",
      " second_conv_1 (Conv1D)      (None, 32, 16)            1808      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                16416     \n",
      "                                                                 \n",
      " output (Dense)              (None, 20)                660       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,816\n",
      "Trainable params: 56,116\n",
      "Non-trainable params: 11,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## creating the model\n",
    "from tensorflow.keras.models import Model, load_model,Sequential\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "inputs = tf.keras.layers.Input((100,))\n",
    "embd_inputs = tf.keras.layers.Embedding(39,300,weights=[embedding_matrix],trainable=False)(inputs)\n",
    "x = tf.keras.layers.Conv1D(16,7,activation=\"relu\",name=\"first_conv\")(embd_inputs)\n",
    "x = tf.keras.layers.Conv1D(16,7,activation=\"relu\",name=\"Second_conv\")(x)\n",
    "x = tf.keras.layers.MaxPool1D()(x)\n",
    "x = tf.keras.layers.Conv1D(16,7,activation=\"relu\",name=\"First_conv_1\")(x)\n",
    "x = tf.keras.layers.Conv1D(16,7,activation=\"relu\",name=\"second_conv_1\")(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(32,activation=\"relu\")(x)\n",
    "outputs = tf.keras.layers.Dense(20,activation=\"softmax\",name=\"output\")(x)\n",
    "\n",
    "model = Model(inputs=inputs,outputs=outputs)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "220/220 [==============================] - 11s 44ms/step - loss: 2.9953 - accuracy: 0.0495 - val_loss: 2.9925 - val_accuracy: 0.0519\n",
      "Epoch 2/50\n",
      "220/220 [==============================] - 13s 60ms/step - loss: 2.9922 - accuracy: 0.0540 - val_loss: 2.9915 - val_accuracy: 0.0556\n",
      "Epoch 3/50\n",
      "220/220 [==============================] - 10s 47ms/step - loss: 2.9903 - accuracy: 0.0586 - val_loss: 2.9881 - val_accuracy: 0.0733\n",
      "Epoch 4/50\n",
      "220/220 [==============================] - 10s 45ms/step - loss: 2.9825 - accuracy: 0.0731 - val_loss: 2.9772 - val_accuracy: 0.0821\n",
      "Epoch 5/50\n",
      "220/220 [==============================] - 11s 49ms/step - loss: 2.9661 - accuracy: 0.0872 - val_loss: 2.9573 - val_accuracy: 0.0941\n",
      "Epoch 6/50\n",
      "220/220 [==============================] - 11s 50ms/step - loss: 2.9443 - accuracy: 0.1014 - val_loss: 2.9392 - val_accuracy: 0.1056\n",
      "Epoch 7/50\n",
      "220/220 [==============================] - 15s 70ms/step - loss: 2.9221 - accuracy: 0.1105 - val_loss: 2.9238 - val_accuracy: 0.1148\n",
      "Epoch 8/50\n",
      "220/220 [==============================] - 11s 50ms/step - loss: 2.8985 - accuracy: 0.1203 - val_loss: 2.9096 - val_accuracy: 0.1218\n",
      "Epoch 9/50\n",
      "220/220 [==============================] - 10s 45ms/step - loss: 2.8794 - accuracy: 0.1298 - val_loss: 2.8990 - val_accuracy: 0.1238\n",
      "Epoch 10/50\n",
      "220/220 [==============================] - 12s 54ms/step - loss: 2.8653 - accuracy: 0.1325 - val_loss: 2.8900 - val_accuracy: 0.1342\n",
      "Epoch 11/50\n",
      "220/220 [==============================] - 13s 57ms/step - loss: 2.8501 - accuracy: 0.1398 - val_loss: 2.8785 - val_accuracy: 0.1334\n",
      "Epoch 12/50\n",
      "220/220 [==============================] - 13s 58ms/step - loss: 2.8325 - accuracy: 0.1409 - val_loss: 2.8714 - val_accuracy: 0.1377\n",
      "Epoch 13/50\n",
      "220/220 [==============================] - 12s 54ms/step - loss: 2.8211 - accuracy: 0.1491 - val_loss: 2.8633 - val_accuracy: 0.1411\n",
      "Epoch 14/50\n",
      "220/220 [==============================] - 14s 65ms/step - loss: 2.8073 - accuracy: 0.1551 - val_loss: 2.8596 - val_accuracy: 0.1430\n",
      "Epoch 15/50\n",
      "220/220 [==============================] - 15s 70ms/step - loss: 2.7996 - accuracy: 0.1584 - val_loss: 2.8524 - val_accuracy: 0.1454\n",
      "Epoch 16/50\n",
      "220/220 [==============================] - 14s 65ms/step - loss: 2.7847 - accuracy: 0.1638 - val_loss: 2.8476 - val_accuracy: 0.1494\n",
      "Epoch 17/50\n",
      "220/220 [==============================] - 14s 64ms/step - loss: 2.7754 - accuracy: 0.1635 - val_loss: 2.8395 - val_accuracy: 0.1520\n",
      "Epoch 18/50\n",
      "220/220 [==============================] - 12s 55ms/step - loss: 2.7613 - accuracy: 0.1714 - val_loss: 2.8357 - val_accuracy: 0.1533\n",
      "Epoch 19/50\n",
      "220/220 [==============================] - 11s 48ms/step - loss: 2.7524 - accuracy: 0.1756 - val_loss: 2.8285 - val_accuracy: 0.1533\n",
      "Epoch 20/50\n",
      "220/220 [==============================] - 11s 51ms/step - loss: 2.7403 - accuracy: 0.1781 - val_loss: 2.8262 - val_accuracy: 0.1580\n",
      "Epoch 21/50\n",
      "220/220 [==============================] - 10s 44ms/step - loss: 2.7308 - accuracy: 0.1809 - val_loss: 2.8229 - val_accuracy: 0.1595\n",
      "Epoch 22/50\n",
      "220/220 [==============================] - 11s 52ms/step - loss: 2.7160 - accuracy: 0.1884 - val_loss: 2.8157 - val_accuracy: 0.1588\n",
      "Epoch 23/50\n",
      "220/220 [==============================] - 12s 52ms/step - loss: 2.7123 - accuracy: 0.1903 - val_loss: 2.8120 - val_accuracy: 0.1597\n",
      "Epoch 24/50\n",
      "220/220 [==============================] - 10s 47ms/step - loss: 2.7036 - accuracy: 0.1951 - val_loss: 2.8101 - val_accuracy: 0.1665\n",
      "Epoch 25/50\n",
      "220/220 [==============================] - 13s 57ms/step - loss: 2.6901 - accuracy: 0.1965 - val_loss: 2.8084 - val_accuracy: 0.1663\n",
      "Epoch 26/50\n",
      "220/220 [==============================] - 13s 58ms/step - loss: 2.6854 - accuracy: 0.2014 - val_loss: 2.8004 - val_accuracy: 0.1678\n",
      "Epoch 27/50\n",
      "220/220 [==============================] - 10s 45ms/step - loss: 2.6764 - accuracy: 0.2038 - val_loss: 2.7952 - val_accuracy: 0.1691\n",
      "Epoch 28/50\n",
      "220/220 [==============================] - 10s 44ms/step - loss: 2.6593 - accuracy: 0.2029 - val_loss: 2.7935 - val_accuracy: 0.1732\n",
      "Epoch 29/50\n",
      "220/220 [==============================] - 10s 43ms/step - loss: 2.6586 - accuracy: 0.2067 - val_loss: 2.7911 - val_accuracy: 0.1740\n",
      "Epoch 30/50\n",
      "220/220 [==============================] - 10s 44ms/step - loss: 2.6471 - accuracy: 0.2094 - val_loss: 2.7884 - val_accuracy: 0.1766\n",
      "Epoch 31/50\n",
      "220/220 [==============================] - 11s 50ms/step - loss: 2.6325 - accuracy: 0.2176 - val_loss: 2.7864 - val_accuracy: 0.1802\n",
      "Epoch 32/50\n",
      "220/220 [==============================] - 15s 68ms/step - loss: 2.6270 - accuracy: 0.2171 - val_loss: 2.7820 - val_accuracy: 0.1794\n",
      "Epoch 33/50\n",
      "220/220 [==============================] - 11s 51ms/step - loss: 2.6169 - accuracy: 0.2230 - val_loss: 2.7780 - val_accuracy: 0.1806\n",
      "Epoch 34/50\n",
      "220/220 [==============================] - 11s 48ms/step - loss: 2.6084 - accuracy: 0.2228 - val_loss: 2.7779 - val_accuracy: 0.1828\n",
      "Epoch 35/50\n",
      "220/220 [==============================] - 11s 48ms/step - loss: 2.5979 - accuracy: 0.2306 - val_loss: 2.7755 - val_accuracy: 0.1843\n",
      "Epoch 36/50\n",
      "220/220 [==============================] - 10s 43ms/step - loss: 2.5845 - accuracy: 0.2299 - val_loss: 2.7769 - val_accuracy: 0.1796\n",
      "Epoch 37/50\n",
      "220/220 [==============================] - 12s 53ms/step - loss: 2.5824 - accuracy: 0.2324 - val_loss: 2.7755 - val_accuracy: 0.1851\n",
      "Epoch 38/50\n",
      "220/220 [==============================] - 10s 45ms/step - loss: 2.5667 - accuracy: 0.2354 - val_loss: 2.7730 - val_accuracy: 0.1864\n",
      "Epoch 39/50\n",
      "220/220 [==============================] - 10s 47ms/step - loss: 2.5660 - accuracy: 0.2350 - val_loss: 2.7695 - val_accuracy: 0.1892\n",
      "Epoch 40/50\n",
      "220/220 [==============================] - 10s 46ms/step - loss: 2.5533 - accuracy: 0.2421 - val_loss: 2.7659 - val_accuracy: 0.1894\n",
      "Epoch 41/50\n",
      "220/220 [==============================] - 11s 49ms/step - loss: 2.5514 - accuracy: 0.2437 - val_loss: 2.7620 - val_accuracy: 0.1954\n",
      "Epoch 42/50\n",
      "220/220 [==============================] - 10s 48ms/step - loss: 2.5306 - accuracy: 0.2513 - val_loss: 2.7625 - val_accuracy: 0.1973\n",
      "Epoch 43/50\n",
      "220/220 [==============================] - 10s 47ms/step - loss: 2.5317 - accuracy: 0.2510 - val_loss: 2.7651 - val_accuracy: 0.1958\n",
      "Epoch 44/50\n",
      "220/220 [==============================] - 10s 45ms/step - loss: 2.5233 - accuracy: 0.2465 - val_loss: 2.7610 - val_accuracy: 0.1967\n",
      "Epoch 45/50\n",
      "220/220 [==============================] - 10s 45ms/step - loss: 2.5220 - accuracy: 0.2488 - val_loss: 2.7585 - val_accuracy: 0.2009\n",
      "Epoch 46/50\n",
      "220/220 [==============================] - 11s 52ms/step - loss: 2.5084 - accuracy: 0.2507 - val_loss: 2.7622 - val_accuracy: 0.2020\n",
      "Epoch 47/50\n",
      "220/220 [==============================] - 10s 44ms/step - loss: 2.5021 - accuracy: 0.2605 - val_loss: 2.7583 - val_accuracy: 0.2003\n",
      "Epoch 48/50\n",
      "220/220 [==============================] - 10s 47ms/step - loss: 2.4905 - accuracy: 0.2620 - val_loss: 2.7605 - val_accuracy: 0.2046\n",
      "Epoch 49/50\n",
      "220/220 [==============================] - 10s 47ms/step - loss: 2.4852 - accuracy: 0.2637 - val_loss: 2.7575 - val_accuracy: 0.2033\n",
      "Epoch 50/50\n",
      "220/220 [==============================] - 10s 45ms/step - loss: 2.4668 - accuracy: 0.2688 - val_loss: 2.7622 - val_accuracy: 0.2071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x167ee05b8e0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Model trained with the dense layers of 64  and filter size of 7\n",
    "epoch = 50\n",
    "batch_size = 64\n",
    "# optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,validation_data=[X_val,y_val],batch_size=batch_size,epochs=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "220/220 [==============================] - 11s 44ms/step - loss: 2.5759 - accuracy: 0.2392 - val_loss: 2.7358 - val_accuracy: 0.2054\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 14s 64ms/step - loss: 2.5296 - accuracy: 0.2482 - val_loss: 2.7395 - val_accuracy: 0.2048\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 14s 61ms/step - loss: 2.4834 - accuracy: 0.2624 - val_loss: 2.7309 - val_accuracy: 0.2093\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 11s 49ms/step - loss: 2.4528 - accuracy: 0.2743 - val_loss: 2.7506 - val_accuracy: 0.2110\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 14s 66ms/step - loss: 2.4201 - accuracy: 0.2824 - val_loss: 2.7347 - val_accuracy: 0.2163\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 13s 59ms/step - loss: 2.3872 - accuracy: 0.2852 - val_loss: 2.7356 - val_accuracy: 0.2140\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 10s 45ms/step - loss: 2.3534 - accuracy: 0.2958 - val_loss: 2.7525 - val_accuracy: 0.2227\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 13s 60ms/step - loss: 2.3310 - accuracy: 0.3071 - val_loss: 2.7333 - val_accuracy: 0.2176\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 11s 50ms/step - loss: 2.2956 - accuracy: 0.3153 - val_loss: 2.7236 - val_accuracy: 0.2195\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 11s 49ms/step - loss: 2.2938 - accuracy: 0.3151 - val_loss: 2.7361 - val_accuracy: 0.2238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x167f0672ee0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since model is not converging fast increasing the learning rate \n",
    "# This model was trained with the dense layers of 64 .\n",
    "epoch = 10\n",
    "batch_size = 64\n",
    "# optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,validation_data=[X_val,y_val],batch_size=batch_size,epochs=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "with increaing the learnign as model tends to converge less model seem to ovefit.\n",
    "So,\n",
    "\n",
    "    Decreasing the parameters in the model.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "220/220 [==============================] - 13s 55ms/step - loss: 2.6341 - accuracy: 0.2096 - val_loss: 2.7480 - val_accuracy: 0.1806\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 12s 53ms/step - loss: 2.6207 - accuracy: 0.2093 - val_loss: 2.7482 - val_accuracy: 0.1841\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 12s 57ms/step - loss: 2.6221 - accuracy: 0.2121 - val_loss: 2.7390 - val_accuracy: 0.1851\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 12s 54ms/step - loss: 2.6164 - accuracy: 0.2177 - val_loss: 2.7366 - val_accuracy: 0.1890\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 15s 67ms/step - loss: 2.5976 - accuracy: 0.2238 - val_loss: 2.7283 - val_accuracy: 0.1868\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 14s 62ms/step - loss: 2.5939 - accuracy: 0.2245 - val_loss: 2.7319 - val_accuracy: 0.1894\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 12s 53ms/step - loss: 2.5986 - accuracy: 0.2232 - val_loss: 2.7299 - val_accuracy: 0.1877\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 12s 52ms/step - loss: 2.5860 - accuracy: 0.2236 - val_loss: 2.7360 - val_accuracy: 0.1896\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 12s 54ms/step - loss: 2.5731 - accuracy: 0.2334 - val_loss: 2.7293 - val_accuracy: 0.1883\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 12s 53ms/step - loss: 2.5762 - accuracy: 0.2278 - val_loss: 2.7230 - val_accuracy: 0.1960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x167f64cdee0>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch = 10   # 10+10 +20\n",
    "batch_size = 64\n",
    "# optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,validation_data=[X_val,y_val],batch_size=batch_size,epochs=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "\n",
    "For the char embedding accuracy didnot increase beyond 20.\n",
    "\n",
    "As, for the test i trained only for the 50 epochs. and some tends to overfit with the difference of 9-10 for val\n",
    "and train data accuracy.\n",
    "\n",
    "After keeping hitting the plateau by the model, i stopped the training process. decrease the learing rate. but result\n",
    "didnot change much.\n",
    "\n",
    "<b> Observation</b> \n",
    "1. char level encoding seems to perform less better than word level encoding.\n",
    "2. Char level encoding can be used when there are more slangs, and data is noisy.\n",
    "\n",
    "Char level embedding vector : <a href = \"https://raw.githubusercontent.com/minimaxir/char-embeddings/master/glove.840B.300d-char.txt\">Char Level encoding vector Github link</a>\n",
    "\n",
    "</pre>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Text Classification Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
